{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capitulo6.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOqKNtuSYNx9iQwAGlTwPLU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msap-uai/PythonDeepLearning/blob/main/Capitulo6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGgDMHgRzc39"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En los capítulos anteriores hemos avanzado que el aprendizaje en una red neu- \n",
        "ronal —que básicamente es un modelo que trata de mapear una entrada (una ima- \n",
        "gen de dígito) a una etiqueta (del número correspondiente)— consiste en aprender \n",
        "sus parámetros **(pesos y sesgos)** observando muchas muestras y su etiqueta co \n",
        "rrespondiente durante el proceso de entrenamiento. \n",
        "\n",
        "Recordemos que una capa aplica a sus datos de entrada los pesos y sesgos que tienen almacenados sus neuronas (lo que hemos llamado parámetros de la capa). \n",
        "\n",
        "El proceso de aprendizaje consiste, por tanto, en encontrar los valores adecuados de estos parámetros. su valor se va ajustando gradualmente. Por \n",
        "tanto, en este contexto, aprender significa encontrar un conjunto de valores para los parámetros de todas las capas en una red, de modo que la red mapee correctamente muestras de entrada a sus etiquetas asociados.\n",
        "\n",
        "La **función de pérdida** coge las predicciones de la red y el valor verdadero (lo que esperaríamos que la red produjera) de \n",
        "la etiqueta y calcula un error cometido en una muestra de entrada específica. Se trata de aprovechar esta medida \n",
        "de error cometido como señal de retroalimentación del sistema para ajustar el \n",
        "valor de los parámetros\n",
        "\n",
        "Este ajuste es precisamente el trabajo que realiza el **optimizador**, que implementa esta «retropropagación» de este error para ajustar los pará- \n",
        "metros de la forma que hemos dicho.  Este es el ciclo de entrenamiento que, \n",
        "repetido un número suficiente de veces, produce valores de peso que minimizan el resultado de la función de pérdida.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cCzplffS5d_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenar nuestra red neuronal, es decir, aprender los valores de nuestros pará- \n",
        "metros (pesos w y sesgos b) es un proceso iterativo de «ir y venir» por las capas \n",
        "de neuronas. A la acción de «ir» propagando hacia adelante la llamaremos forward \n",
        "propagation y a la de «venir» retropropagando información en la red la llamaremos \n",
        "back propagation.\n",
        "\n",
        "La primera fase, forward propagation, se da cuando se expone la red a los datos \n",
        "de entrenamiento y estos cruzan toda la red neuronal para calcular sus predic- \n",
        "ciones o etiquetas (labels en inglés). Es decir, cuando se pasan los datos de en- \n",
        "trada a través de la red, de tal manera que todas las neuronas apliquen su transfor- \n",
        "mación a la información que reciben de las neuronas de la capa anterior y la envíen \n",
        "a las neuronas de la capa siguiente. Cuando los datos hayan cruzado todas las \n",
        "capas, y todas sus neuronas hayan realizado sus cálculos, se llegará a la capa final \n",
        "con un resultado de predicción de la etiqueta para aquellas muestras de entrada. \n",
        "A continuación, usaremos una función de pérdida (loss) para calcular el error de \n",
        "estimación, que mide cuán bueno/malo fue nuestro resultado de la predicción en \n",
        "relación con el resultado correcto (recordemos que estamos en un entorno de \n",
        "aprendizaje supervisado y que disponemos de la etiqueta que nos indica el valor \n",
        "esperado). \n",
        "Idealmente, queremos que nuestro error calculado sea cero, es decir, sin diver- \n",
        "gencia entre lo estimado y lo esperado. Y eso se consigue a medida que se entrena \n",
        "el modelo que irá ajustando los pesos de las interconexiones de las neuronas, gra- \n",
        "cias a que se propaga hacia atrás la información del error cometido en la esti- \n",
        "mación. De ahí su nombre, retropropagación, en inglés backward propagation \n",
        "\n",
        "\n",
        "Ahora que ya hemos propagado hacia atrás esta información calculada por la \n",
        "función de pérdida, podemos ajustar los pesos de las conexiones entre neuronas. \n",
        "Lo que estamos haciendo es que el error calculado se reduzca la próxima vez que \n",
        "volvamos a usar la red para una predicción. Para ello usaremos una técnica lla\n",
        "mada descenso del gradiente (Gradient Descent en inglés), que ajusta \n",
        "gradualmente los parámetros del modelo para minimizar la función de coste sobre \n",
        "el conjunto de datos entrenamiento.\n"
      ],
      "metadata": {
        "id": "u9ck596J62ZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recapitulando, el algoritmo de aprendizaje consiste en: \n",
        " \n",
        "1. Empezar con unos valores (a menudo aleatorios) para los parámetros de la \n",
        "red (pesos w j y sesgos b j ). \n",
        "2. Coger un conjunto de ejemplos de datos de entrada (lotes) y pasarlos por la \n",
        "red para obtener su predicción. \n",
        "3. Comparar estas predicciones obtenidas con los valores de etiquetas espe- \n",
        "radas y, con ellas, calcular el error cometido mediante la función de pérdida. \n",
        "4. Propagar hacia atrás este error para que llegue a todos y cada uno de los \n",
        "parámetros que conforman el modelo de la red neuronal. \n",
        "5. Usar esta información propagada para actualizar —con el algoritmo des- \n",
        "censo del gradiente— los parámetros de la red neuronal, de manera que re- \n",
        "duzca el error calculado si lo volvemos a calcular. \n",
        "6. Continuar iterando en los anteriores pasos hasta que consideremos que \n",
        "tenemos un buen modelo (más adelante veremos cuándo debemos parar)."
      ],
      "metadata": {
        "id": "k4BL0b5s7ckU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', \n",
        "              optimizer='sgd', \n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gUK8Fjo_63Bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se pasan tres argumentos: una función de pérdida (argumento loss), un op- \n",
        "timizador (argumento optimizer) y la lista de métricas (argumento metrics), que \n",
        "usaremos para la evaluación del modelo. "
      ],
      "metadata": {
        "id": "Hr3Dz7YO7tN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent algunas variantes que se usan: \n",
        "1. descenso del gradiente en lotes (Bath Gradient Descent en inglés), \n",
        "2. descenso del gradiente en minilotes (Mini Bath Gradient Descent en inglés) y \n",
        "3. descenso del gradiente estocástico (Stochastic Gradient Descent en inglés).\n",
        "\n"
      ],
      "metadata": {
        "id": "6EY9fXKO8E_o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OPTIMIZER"
      ],
      "metadata": {
        "id": "vPwM3Sx192Z3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Descenso del gradiente es un algoritmo de optimización genérico capaz de encon- \n",
        "trar soluciones óptimas a una amplia gama de problemas. La idea general del des \n",
        "censo del gradiente es ajustar parámetros de forma iterativa para minimizar una \n",
        "función de pérdida. (derivada primera)\n",
        "\n",
        "El primer caso es el caso del descenso del gradiente estocástico (**SGD** del in- \n",
        "glés Stochastic Gradient Descent), cuando se estima el gradiente a partir del error observado para cada muestra del entrenamiento. El término estocástico se refiere al hecho de que cada dato se extrae al azar (estocástico es un sinónimo científico de aleatorio). \n",
        "\n",
        "Mientras que el segundo se conoce como descenso del gradiente en lotes (en \n",
        "inglés **Batch Gradient Descent**), y se da cuando usamos todo el conjunto de datos \n",
        "de entrenamiento en cada paso del algoritmo de optimización, que calcula el error con la función de pérdida. La literatura indica que se pueden obtener mejores resultados con el primer caso. \n",
        "\n",
        "una tercera opción, que ajusta los parámetros con un subconjunto de muestras del conjunto de entrenamiento, conocida como descenso del gradiente en minilotes (**Mini Bath Gradient Descent** en inglés). \n",
        "Esta opción suele ser mejor que la de descenso del gradiente estocástico y se \n",
        "requieren menos cálculos para actualizar los parámetros de la red neuronal.\n",
        "\n"
      ],
      "metadata": {
        "id": "QXD0M9nd8W1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD es muy fácil de implementar en Keras. En el método compile() se indica \n",
        "que el optimizador es descenso del gradiente estocástico (valor sgd en el argu- \n",
        "mento), y en el método fit() se especifica el tamaño del lote (batch) que cogeremos \n",
        "a cada iteración en el argumento batch_size, como se muestra en la siguiente línea \n",
        "de código:\n",
        "\n",
        "**model.fit(X_train, y_train, epochs=5, batch_size=100)** \n",
        " \n",
        "En este ejemplo de código, estamos dividiendo nuestros datos en lotes de ta- \n",
        "maño 100 con el argumento de batch_size. Con el argumento epochs estamos \n",
        "indicando cuántas veces realizamos este proceso sobre todos los datos. En futu- \n",
        "ros capítulos, cuando ya hayamos presentado los optimizadores, volveremos a ha- \n",
        "blar de estos dos argumentos (epochs y batch_size) con más detalle."
      ],
      "metadata": {
        "id": "QaB4lqIl9plD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " En TensorFlow, con la API de Keras se pueden usar otros optimi- \n",
        "zadores, además del SGD ya presentado: RMSprop, AdaGrad, Adadelta, Adam, \n",
        "Adamax, Nadam. \n",
        "\n",
        "* AdaGrad mejora el algoritmo de descenso del gradiente cuan- \n",
        "do tenemos varias dimensiones (el ejemplo visual que hemos considerado solo \n",
        "tiene una, pero en realidad hay muchas dimensiones). \n",
        "* el algoritmo RMSProp que, excepto en problemas \n",
        "muy simples, es un optimizador que casi siempre funciona mucho mejor que Ada- \n",
        "Grad. \n"
      ],
      "metadata": {
        "id": "313VIQHX_m8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop \n",
        "  \n",
        "my_optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model.compile(optimizer= my_optimizer, \n",
        "              loss='binary_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "REk147X29ndu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LOSS\n",
        "\n",
        "Una función de pérdida (loss function en inglés) es necesaria para guiar el proceso \n",
        "de entrenamiento de la red presentado en la sección anterior, y para cuantificar lo \n",
        "cercana que está una determinada red neuronal de su ideal mientras está en el pro- \n",
        "ceso de entrenamiento.\n",
        "\n",
        "la elección de la función \n",
        "de pérdida debe coincidir con el problema específico de modelado predictivo—, \n",
        "tales como regresión o clasificación,\n",
        "\n",
        "* **categorical_crossentropy** como función de pérdida, ya que nuestra salida debe ser en formato **categórico**. Y en este caso, además, la salida de la capa final debe pasar a través de una función de activación **softmax** para que cada nodo genere un valor de probabilidad entre 0 y 1.\n",
        "* sparse_categorical_crossentropy / softmax\n",
        "* cuando tenemos una tarea de clasificación **binaria**,  una de las funciones de pérdida que se suele usar es **binary_crossentropy**. Si usamos esta función de pérdida, solo necesitamos un nodo de salida para clasificar los datos en dos clases. El valor de salida debe pasar a través de una función de activación **sigmoid**, y el rango de salida debe ser entre 0 y 1.\n",
        "* Mean Squared Error. Como su nombre indica, esta pérdida se calcula tomando la media de las diferencias al cuadrado entre los valores reales y los pronosticados. \n",
        "\n",
        "\n",
        "La elección de la mejor función de pérdida reside en entender qué tipo de error \n",
        "es o no es aceptable para el problema en concreto. "
      ],
      "metadata": {
        "id": "SyI5FaOd97EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ydMABO3y7tqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N8BWapqy_d5z"
      }
    }
  ]
}